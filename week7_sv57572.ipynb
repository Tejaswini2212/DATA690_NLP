{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1"
      ],
      "metadata": {
        "id": "HSsvmnZuMtQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9EXm5s3NAgL",
        "outputId": "1bd47842-8ffe-4f5e-dbe0-2732d9b6d5c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GHRKeDOHMAxJ"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Loading Burbank text\n",
        "with open(\"Burbank.txt\", \"r\") as f:\n",
        "    burbank_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blob = TextBlob(burbank_text)\n",
        "sentiment = blob.sentiment\n",
        "\n",
        "# Polarity ranges from negative -1 to positive +1\n",
        "print(\"Polarity:\", sentiment.polarity)\n",
        "\n",
        "# Approx prob of being negative (if polarity < 0)\n",
        "prob_negative = max(0, -sentiment.polarity)\n",
        "print(\"Estimated prob of negative sentiment:\", prob_negative)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvcUKnyzMIIB",
        "outputId": "06822d71-cd74-4dd5-840c-f7881d6ae573"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polarity: 0.09869334480780263\n",
            "Estimated prob of negative sentiment: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2"
      ],
      "metadata": {
        "id": "XWM_cP6_MxG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Polarity:\", blob.sentiment.polarity)      # -1 to 1\n",
        "print(\"Subjectivity:\", blob.sentiment.subjectivity)  # 0 (objective) to 1 (subjective)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKFJGCl9MQ8z",
        "outputId": "2fd12eb7-14d1-4216-f80c-2361c0fefaf1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polarity: 0.09869334480780263\n",
            "Subjectivity: 0.3790877796901893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 3"
      ],
      "metadata": {
        "id": "cFi_pinyM2z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import Word\n",
        "\n",
        "words = [Word(word.lower()) for word in blob.words if word.isalpha()]\n",
        "word_freq = {}\n",
        "for word in words:\n",
        "    word_freq[word] = word_freq.get(word, 0) + 1\n",
        "\n",
        "# Sorting to get top 10 frequent words (naive topic extraction)\n",
        "top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "print(\"Top key topics:\")\n",
        "for word, freq in top_words:\n",
        "    print(f\"{word} ➔ {freq}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGR0WCHlMzow",
        "outputId": "2b9d2d66-cab2-4902-87f7-347c34f9bf96"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top key topics:\n",
            "the ➔ 114\n",
            "of ➔ 50\n",
            "to ➔ 39\n",
            "and ➔ 36\n",
            "that ➔ 21\n",
            "in ➔ 20\n",
            "a ➔ 18\n",
            "faa ➔ 13\n",
            "burbank ➔ 12\n",
            "said ➔ 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 4"
      ],
      "metadata": {
        "id": "ayEur_U9NIl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "TiGdLBoSM586"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading each dataset\n",
        "amazon = pd.read_csv(\"amazon_cells_labelled.txt\", sep=\"\\t\", header=None, names=[\"Review\", \"Label\"])\n",
        "imdb = pd.read_csv(\"imdb_labelled.txt\", sep=\"\\t\", header=None, names=[\"Review\", \"Label\"])\n",
        "yelp = pd.read_csv(\"yelp_labelled.txt\", sep=\"\\t\", header=None, names=[\"Review\", \"Label\"])\n"
      ],
      "metadata": {
        "id": "azgF9Wu_NhG0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding company labels\n",
        "amazon[\"Company\"] = \"Amazon\"\n",
        "imdb[\"Company\"] = \"IMDB\"\n",
        "yelp[\"Company\"] = \"Yelp\"\n",
        "\n",
        "# Combining\n",
        "comb_data = pd.concat([amazon, imdb, yelp], ignore_index=True)\n",
        "print(comb_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7nJxV4uNj1G",
        "outputId": "63cd879c-8107-4aa9-f303-03b1b5a6f156"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Review  Label Company\n",
            "0  So there is no way for me to plug it in here i...      0  Amazon\n",
            "1                        Good case, Excellent value.      1  Amazon\n",
            "2                             Great for the jawbone.      1  Amazon\n",
            "3  Tied to charger for conversations lasting more...      0  Amazon\n",
            "4                                  The mic is great.      1  Amazon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comb_data.to_csv(\"Sentiment_Analysis_Dataset.csv\", index=False)\n",
        "print(\"Columns:\", comb_data.columns.tolist())\n",
        "print(\"Null values:\\n\", comb_data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvyD70YNNluq",
        "outputId": "615665b2-55ba-4f36-ab77-3c729a3a56b1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: ['Review', 'Label', 'Company']\n",
            "Null values:\n",
            " Review     0\n",
            "Label      0\n",
            "Company    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import string\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stopwords = list(STOP_WORDS)\n",
        "punctuations = string.punctuation\n",
        "\n",
        "def clean_text(text):\n",
        "    doc = nlp(text.lower())\n",
        "    return \" \".join([token.lemma_ for token in doc if token.text not in stopwords and token.text not in punctuations])\n"
      ],
      "metadata": {
        "id": "3WSYEqSrOZoq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "b7ENA5H_Of3e"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(comb_data['Review'], comb_data['Label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Custom transformer\n",
        "class predictors(TransformerMixin):\n",
        "    def transform(self, X, **transform_params):\n",
        "        return [clean_text(text) for text in X]\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "    def get_params(self, deep=True):\n",
        "        return {}"
      ],
      "metadata": {
        "id": "K10sQT7POmA_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building pipeline\n",
        "pipe_countvect = Pipeline([\n",
        "    (\"cleaner\", predictors()),\n",
        "    (\"vectorizer\", TfidfVectorizer()),\n",
        "    (\"classifier\", LinearSVC())\n",
        "])\n",
        "\n",
        "# Training\n",
        "pipe_countvect.fit(X_train, y_train)\n",
        "\n",
        "# Predicting\n",
        "y_pred = pipe_countvect.predict(X_test)\n",
        "print(\"Accuracy on test data:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3kWpKdgOogE",
        "outputId": "25e05c28-1d08-4095-9f84-1fe586ee04a0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test data: 0.8072727272727273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \"This product is wonderful!\"\n",
        "pred = pipe_countvect.predict([sample])[0]\n",
        "print(sample, \"Prediction ➔\", pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-Exo84yOpJX",
        "outputId": "89296351-632f-4d6d-f88d-13b3a7d173ce"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This product is wonderful! Prediction ➔ 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eV3DnRrEOxUZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}